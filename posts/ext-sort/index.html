<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Rust Adventures: External Sort, Chapter 1 | nerv</title>
<meta name=keywords content="rust,algorithms">
<meta name=description content="I&rsquo;ve been learning Rust in my free time for the last 6 months. I read The Book and I&rsquo;m in the middle of reading Rust for Rustaceans (my notes so far ), but after doing a couple of very small exercises and projects I wanted to do something more rusty.
So on Sundays, in between espressos and with very good company, I started writing an external sort.
This is the 1st post in a series, where I cover the code that generates the data to be sorted.">
<meta name=author content>
<link rel=canonical href=http://0x5d.github.io/posts/ext-sort/>
<link crossorigin=anonymous href=/assets/css/stylesheet.6a98292fb8fa8cf0f3ba4042d4b75515c04267550f3ad49ff6271b5af9562443.css integrity="sha256-apgpL7j6jPDzukBC1LdVFcBCZ1UPOtSf9icbWvlWJEM=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=http://0x5d.github.io/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=http://0x5d.github.io/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=http://0x5d.github.io/favicon-32x32.png>
<link rel=apple-touch-icon href=http://0x5d.github.io/apple-touch-icon.png>
<link rel=mask-icon href=http://0x5d.github.io/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<link rel=alternate hreflang=en href=http://0x5d.github.io/posts/ext-sort/>
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript><meta property="og:title" content="Rust Adventures: External Sort, Chapter 1">
<meta property="og:description" content="I&rsquo;ve been learning Rust in my free time for the last 6 months. I read The Book and I&rsquo;m in the middle of reading Rust for Rustaceans (my notes so far ), but after doing a couple of very small exercises and projects I wanted to do something more rusty.
So on Sundays, in between espressos and with very good company, I started writing an external sort.
This is the 1st post in a series, where I cover the code that generates the data to be sorted.">
<meta property="og:type" content="article">
<meta property="og:url" content="http://0x5d.github.io/posts/ext-sort/"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2024-11-16T20:19:47-05:00">
<meta property="article:modified_time" content="2024-11-16T20:19:47-05:00">
<meta name=twitter:card content="summary">
<meta name=twitter:title content="Rust Adventures: External Sort, Chapter 1">
<meta name=twitter:description content="I&rsquo;ve been learning Rust in my free time for the last 6 months. I read The Book and I&rsquo;m in the middle of reading Rust for Rustaceans (my notes so far ), but after doing a couple of very small exercises and projects I wanted to do something more rusty.
So on Sundays, in between espressos and with very good company, I started writing an external sort.
This is the 1st post in a series, where I cover the code that generates the data to be sorted.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://0x5d.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Rust Adventures: External Sort, Chapter 1","item":"http://0x5d.github.io/posts/ext-sort/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Rust Adventures: External Sort, Chapter 1","name":"Rust Adventures: External Sort, Chapter 1","description":"I\u0026rsquo;ve been learning Rust in my free time for the last 6 months. I read The Book and I\u0026rsquo;m in the middle of reading Rust for Rustaceans (my notes so far ), but after doing a couple of very small exercises and projects I wanted to do something more rusty.\nSo on Sundays, in between espressos and with very good company, I started writing an external sort.\nThis is the 1st post in a series, where I cover the code that generates the data to be sorted.","keywords":["rust","algorithms"],"articleBody":"I’ve been learning Rust in my free time for the last 6 months. I read The Book and I’m in the middle of reading Rust for Rustaceans (my notes so far ), but after doing a couple of very small exercises and projects I wanted to do something more rusty.\nSo on Sundays, in between espressos and with very good company, I started writing an external sort.\nThis is the 1st post in a series, where I cover the code that generates the data to be sorted. Stay tuned for the next one!\n All the code \u0026 commands I’ll post here are running on my Macbook Pro M1 (32GiB, 1TB SSD). This is just for fun. The code is hosted in GitHub .\n The problem External sorting algorithms are used when the data that must be sorted can’t fit in memory. For example, my Mac has 32GiB of RAM. How can I sort a larger file?\nSo the basic idea is:\n you get a big file (bigger than memory), you split it into smaller chunks that fit in memory, you sort those chunks and write them to disk, you merge the sorted chunks and write the output, sorted.  I will go deeper into details as we go into my implementation.\nThe Solution Goals\n Make this thing fast af. Drink good espresso. Go into rabbit holes, learn about hardware, the OS, and performance.  Non-goals\n To write a production-ready Rust crate. This is just a fun exercise.  Sorting lots of random data Hold on, to sort lots of random data we need to start by -\nGenerating lots of random data  Soundtrack: Turnstile - Generator  Ok, so the first thing we need is a way to generate random data. For this project, we’ll consider a 4KiB (AKA a “page”) ASCII string a unit or block of data. This will be the resolution we’ll be working at. The source file will be composed of many 4KiB strings with no gaps or delimiters.\nWriting* lots of random data fast* One of the Goals is to make this thing fast. So let’s think about that for a second - what does fast mean in this context? What determines the higher bound for time in this algorithm? It requires 3 things:\n Memory CPU IO (SSD)  If the input grows, we could add more CPU and memory, but IO speeds would remain constant - NVMe SSDs have a physical write speed limit, so we’ll probably be limited by it. Let’s see what that looks like.\nHow “fast” is “slow”? There are some unofficial sources which have published benchmarks for Apple MacBook Pro SSDs, but I wanna check by myself.\nTo do so, I’ll use fio (the Flexible IO CLI, but nobody I know calls it that), a disk benchmark tool. It has a lot of knobs (it’s flexible!), and I encourage you to run man fio to check them out. However, we’re only interested in knowing the write rate (mebibytes per second), so this is how we’ll run it:\nNOTE: The following command will create a 100GiB file in the directory where its run. Think before you run it!\nfio --name=write \\  --ioengine=posixaio \\  --rw=write \\  --bs=1m \\  --numjobs=1 \\  --size=100g \\  --iodepth=8 \\  --end_fsync=1 \\  --direct=1 Flags explanation\n --name=write: Just a name for the fio “job”. It will use it for the output and the file it creates. --ioengine=posixaio: The IO engine for MacOS, POSIX Asynchronous IO. --rw=write: We’re only interested in measuring performance with sequential writes. --bs=1m: A block size of 1MiB. If it was smaller, fio would need to make lots of repeated write syscalls, adding a lot of noise to the test (since they’re expensive - more on this later). --numjobs=1: The number of parallel jobs performing IO (writing, in this case). Since we’re doing sequential IO, adding more jobs won’t do any good - they’ll contend for file access. --size=100g: A big file! --iodepth=16: The queue of in-flight IO operations against the file. This is determined by a combination of the OS, the fio engine (posixaio in this case), and other factors. fio’s output shows a distribution of the queue size, which helps determine the maximum value here. If a smaller-than-possible value is used, the benchmark might spend lots of time waiting for IO operations to be acknowledged. A value of 1 would make it behave synchronously. --end_fsync=1: Only consider the test done when the file is flushed to disk. --direct=1: Use direct IO (as opposed to buffered IO). In MacOS, this is controlled by fcntl’s F_NOCACHE flag (see man fcntl). In Linux, this is equivalent to setting the O_DIRECT flag when opening a file.  I will omit most of the output since right now we’re only looking for the average write rate, expressed by the bw (bandwidth) output field, which in this case is ~5736MiB/s (I averaged it over multiple runs). If you’re curious about what the rest of the output means, the official docs have a great explanation.\nSo now that we know the practical upper limit that we can hit with the generator, we can move on to it.\nConsiderations File size Simple one. We’ll allow the file size to be configurable. However, since we’re treating a 4KiB block as our unit, the file size will be 4KiB-aligned (that is, we must check that its size is a multiple of 4KiB).\nMemory limit The reason for using an external sorting algorithm is not having enough memory to hold the data being sorted. Therefore, we need to take care not to go over the available memory. We’ll allow it to be configurable via a flag.\nParallelism Generating random ASCII strings will be slow, so we’ll benefit from using multiple threads. We’ll use Tokio for that.\nSaturation The SSD must be saturated at all times, so that we don’t add artificial bottlenecks.\nThe code The strategy I followed is as follows:\n Create the file. In MacOS, the file is opened with Direct IO by default. In Linux, you’ll need to be careful to open it with the O_DIRECT flag set. Spawn a “writer” thread. It will hold a handle to the open file and receive strings over a channel, which it will write to the file. Since the strings are random, it won’t do any ordering, writing them in a FIFO fashion. Start threads to generate the random strings, sending them over the channel. This is where memory is allocated, so we must have a way to enforce the configured limit.  Sidequest: limiting memory  To make it easier to enforce the memory limit, I wrote a simple rate-limiting token bucket .\nIt’s initialized with a capacity, and threads can take and put tokens back. If a thread tries to take a token when the bucket doesn’t have any, it will sleep until a token is put back by another thread.\nThe implementation isn’t perfect (e.g. it doesn’t prevent putting tokens over the initial capacity), but it’s enough.\nBack to the main thing Ok, back to random string generation. Here’s the code in full. I’ll go over each part.\n First, the signature:\npub async fn generate_data(filepath: \u0026str, size_bytes: usize, max_mem: usize) - io::Result() generate_data is an async function. It takes a filepath where the file will be created, the file’s size, size_bytes, and the program’s memory limit: max_mem. It returns an io::Result to communicate that it can fail.\nif (max_mem as usize)  crate::BLOCK_SIZE { return io::Result::Err(Error::new( io::ErrorKind::Other, format!( \"Max allowed memory must be larger than {}B\", crate::BLOCK_SIZE ), )); } The max memory must be at least 1 block (4096B) - otherwise we won’t be able to do anything! Here’s a good place to make it clear that max_mem doesn’t account for the memory things on the stack - pointers, numbers, etc.\nlet file = File::create(filepath)?; let num_cores = std::thread::available_parallelism()?.get(); let mem_per_core = max_mem / num_cores; let b = Arc::new(bucket::Bucket::new(num_cores as i32)); let mut set = JoinSet::new(); let (tx, rx) = mpsc::channel(); Next up, the values used throughout the function at are initialized:\n file: The file into which we’ll write the random strings. num_cores: The number of cores available in the CPU. mem_per_core: The maximum amount of memory (in bytes) that each thread will be able to use. b: The Bucket that will serve as the memory-limiting mechanism. It’s wrapped in an Arc so that it can be “shared” across threads. set: A Tokio JoinSet, which we’ll use to keep track of the threads, and to join them when work is finished. tx, rx: The send and receive ends of a channel, which we’ll use to transmit strings from the “generator” threads to the “writer” thread.  About that…\nlet writer_handle = tokio::spawn(writer(file, b.clone(), rx, num_cores)); // ... async fn writer( mut file: File, b: ArcBucket, rx: ReceiverString, ) - io::Result() { loop { let s = rx.recv().map_err(|e| { Error::new( ErrorKind::Other, format!(\"Could not receive from channel: {e}\"), ) })?; if s == POISON_PILL { return Ok(()); } b.put(); file.write_all(s.as_bytes())?; } } The writer thread writes the strings it receives over rx, and puts back a token into the bucket, so any waiting generator threads are unblocked. When generation is finished, a POISON_PILL value is sent, signaling it to stop.\nNow, onto the main loop in generate_data:\nlet mut remaining = size_bytes; while remaining  0 { let len = min(remaining, mem_per_core); remaining -= len; let tx = tx.clone(); b.take(); set.spawn_blocking(move || generate(tx, len)); } Here, a new generator task is spawned for every chunk of string that must be generated, until there are no more remaining bytes. The string will be at most mem_per_core long. A token is taken from the bucket b, to prevent the program from going over the max_mem. generate is called, which generates a random string and sends it over tx so that the writer thread writes it to the file.\nwhile let Some(res) = set.join_next().await { let _ = res??; } tx.send(String::from(POISON_PILL)) .map_err(|e| io::Error::new(ErrorKind::Other, e))?; writer_handle.await? Finally, we join all the generator tasks, send the POISON_PILL message to the writer, and join it.\nThe moment of truth According to the write rate output by fio (5736MiB/s), just writing 100GiB file should take around ~17.9 seconds. We should expect some overhead from the random string generation, though.\nI created a small CLI with the clap crate to make it easier to generate the file. Wrapping the call with time gives us:\ntime ./target/release/ext-sort gen --file data.txt --size 107374182400 ./target/release/ext-sort gen --file data.txt --size 107374182400 176.07s user 21.10s system 924% cpu 21.323 total That’s just over 3 seconds more than fio, which is a little bit of overhead. If you see any chances for reducing it, please let me know over at Twitter or Bluesky !\nThe real friends were the walls we crashed into along the way  Soundtrack: Turnstile - Endless When I hit a wall I gotta BREAK. IN.\n Here are some things I ran into.\nAlways use --profile release … before you test performance. cargo build on its own doesn’t apply all possible optimizations, to make compilation faster. The result is abysmal:\ncargo build time ./target/debug/ext-sort gen --file data.txt --size 107374182400 ./target/debug/ext-sort gen --file data.txt --size 107374182400 1825.21s user 28.37s system 963% cpu 3:12.48 total 3:12.48! That’s over 9x more than with the release build.\nJoinSet::spawn_blocking vs JoinSet::spawn Using spawn_blocking yields slightly faster (~600ms for 100GiB files) run times than spawn in this case. This caught me off-guard at first, but upon inspection, this probably happens because in generate, SmallRng::from_entropy() issues a system call to getentropy (getrandom in Linux).\nFile::write vs File::write_all The write docstring says it clearly:\n This function will attempt to write the entire contents of buf, but the entire write might not succeed […]\n So if you wanna make sure the whole buffer is written to the file, call write_all (or do what write_all does, which is to call write as many times as needed).\n","wordCount":"1972","inLanguage":"en","datePublished":"2024-11-16T20:19:47-05:00","dateModified":"2024-11-16T20:19:47-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://0x5d.github.io/posts/ext-sort/"},"publisher":{"@type":"Organization","name":"nerv","logo":{"@type":"ImageObject","url":"http://0x5d.github.io/favicon.ico"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=http://0x5d.github.io/ accesskey=h title="nerv (Alt + H)">nerv</a>
<div class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
<ul class=lang-switch><li>|</li>
<li>
<a href=http://0x5d.github.io/es/ title=Español aria-label=Español>Es</a>
</li>
</ul>
</div>
</div>
<ul id=menu>
<li>
<a href=http://0x5d.github.io/archive/ title=archive>
<span>archive</span>
</a>
</li>
<li>
<a href=http://0x5d.github.io/search/ title="search (Alt + /)" accesskey=/>
<span>search</span>
</a>
</li>
<li>
<a href=http://0x5d.github.io/tags/ title=tags>
<span>tags</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<h1 class=post-title>
Rust Adventures: External Sort, Chapter 1
</h1>
<div class=post-meta><span title="2024-11-16 20:19:47 -0500 -0500">November 16, 2024</span>&nbsp;·&nbsp;10 min
</div>
</header> <div class=toc>
<details>
<summary accesskey=c title="(Alt + C)">
<span class=details>Table of Contents</span>
</summary>
<div class=inner><ul>
<li>
<a href=#the-problem aria-label="The problem">The problem</a></li>
<li>
<a href=#the-solution aria-label="The Solution">The Solution</a><ul>
<li>
<a href=#sorting-lots-of-random-data aria-label="Sorting lots of random data">Sorting lots of random data</a></li>
<li>
<a href=#generating-lots-of-random-data aria-label="Generating lots of random data">Generating lots of random data</a><ul>
<li>
<a href=#writing-lots-of-random-data-fast aria-label="Writing* lots of random data fast*">Writing* lots of random data fast*</a></li>
<li>
<a href=#how-fast-is-slow aria-label="How &amp;ldquo;fast&amp;rdquo; is &amp;ldquo;slow&amp;rdquo;?">How &ldquo;fast&rdquo; is &ldquo;slow&rdquo;?</a></li>
<li>
<a href=#considerations aria-label=Considerations>Considerations</a><ul>
<li>
<a href=#file-size aria-label="File size">File size</a></li>
<li>
<a href=#memory-limit aria-label="Memory limit">Memory limit</a></li>
<li>
<a href=#parallelism aria-label=Parallelism>Parallelism</a></li>
<li>
<a href=#saturation aria-label=Saturation>Saturation</a></li></ul>
</li>
<li>
<a href=#the-code aria-label="The code">The code</a><ul>
<li>
<a href=#sidequest-limiting-memory aria-label="Sidequest: limiting memory">Sidequest: limiting memory</a></li>
<li>
<a href=#back-to-the-main-thing aria-label="Back to the main thing">Back to the main thing</a></li></ul>
</li>
<li>
<a href=#the-moment-of-truth aria-label="The moment of truth">The moment of truth</a></li></ul>
</li>
<li>
<a href=#the-real-friends-were-the-walls-we-crashed-into-along-the-way aria-label="The real friends were the walls we crashed into along the way">The real friends were the walls we crashed into along the way</a><ul>
<li>
<a href=#always-use---profile-release aria-label="Always use --profile release">Always use <code>--profile release</code></a></li>
<li>
<a href=#joinsetspawn_blocking-vs-joinsetspawn aria-label="JoinSet::spawn_blocking vs JoinSet::spawn">JoinSet::spawn_blocking vs JoinSet::spawn</a></li>
<li>
<a href=#filewrite-vs-filewrite_all aria-label="File::write vs File::write_all">File::write vs File::write_all</a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</details>
</div>
<div class=post-content><p>I&rsquo;ve been learning Rust in my free time for the last 6 months. I read The Book and I&rsquo;m in the middle of reading Rust for Rustaceans (<a href=https://blog.nerv.industries/posts/rust-for-rustaceans/ target=_blank>my notes so far</a>
), but after doing a couple of very small exercises and projects I wanted to do something more <em>rusty</em>.</p>
<p>So on Sundays, in between espressos and with very good company, I started writing an external sort.</p>
<p>This is the 1st post in a series, where I cover the code that generates the data to be sorted. Stay tuned for the next one!</p>
<blockquote>
<p>All the code & commands I&rsquo;ll post here are running on my Macbook Pro M1 (32GiB, 1TB SSD). This is just for fun.
The code is hosted in <a href=https://github.com/0x5d/ext-sort target=_blank>GitHub</a>
.</p>
</blockquote>
<h1 id=the-problem>The problem<a hidden class=anchor aria-hidden=true href=#the-problem>#</a></h1>
<p><a href=https://en.wikipedia.org/wiki/External_sorting target=_blank>External sorting</a>
algorithms are used when the data that must be sorted can&rsquo;t fit in memory. For example, my Mac has 32GiB of RAM. How can I sort a larger file?</p>
<p>So the basic idea is:</p>
<ul>
<li>you get a big file (bigger than memory),</li>
<li>you split it into smaller chunks that fit in memory,</li>
<li>you sort those chunks and write them to disk,</li>
<li>you merge the sorted chunks and write the output, sorted.</li>
</ul>
<p>I will go deeper into details as we go into my implementation.</p>
<h1 id=the-solution>The Solution<a hidden class=anchor aria-hidden=true href=#the-solution>#</a></h1>
<p><strong>Goals</strong></p>
<ul>
<li>Make this thing <strong>fast</strong> af.</li>
<li>Drink good espresso.</li>
<li>Go into rabbit holes, learn about hardware, the OS, and performance.</li>
</ul>
<p><strong>Non-goals</strong></p>
<ul>
<li>To write a production-ready Rust crate. This is just a fun exercise.</li>
</ul>
<h2 id=sorting-lots-of-random-data>Sorting lots of random data<a hidden class=anchor aria-hidden=true href=#sorting-lots-of-random-data>#</a></h2>
<p>Hold on, to sort lots of random data we need to start by -</p>
<h2 id=generating-lots-of-random-data>Generating lots of random data<a hidden class=anchor aria-hidden=true href=#generating-lots-of-random-data>#</a></h2>
<blockquote>
<p>Soundtrack: <a href="https://www.youtube.com/watch?v=MDRUwlqa6N0" target=_blank>Turnstile - Generator</a>
</p>
</blockquote>
<p>Ok, so the first thing we need is a way to generate random data. For this project, we&rsquo;ll consider a 4KiB (AKA a &ldquo;page&rdquo;) ASCII string a <em>unit</em> or <em>block</em> of data. This will be the resolution we&rsquo;ll be working at. The source file will be composed of many 4KiB strings with no gaps or delimiters.</p>
<h3 id=writing-lots-of-random-data-fast>Writing* lots of random data fast*<a hidden class=anchor aria-hidden=true href=#writing-lots-of-random-data-fast>#</a></h3>
<p>One of the <strong>Goals</strong> is to make this thing fast. So let&rsquo;s think about that for a second - what does <em>fast</em> mean in this context? What determines the higher bound for time in this algorithm? It requires 3 things:</p>
<ul>
<li>Memory</li>
<li>CPU</li>
<li>IO (SSD)</li>
</ul>
<p>If the input grows, we <em>could</em> add more CPU and memory, but IO speeds would remain constant - NVMe SSDs have a physical write speed limit, so we&rsquo;ll probably be limited by it. Let&rsquo;s see what that looks like.</p>
<h3 id=how-fast-is-slow>How &ldquo;fast&rdquo; is &ldquo;slow&rdquo;?<a hidden class=anchor aria-hidden=true href=#how-fast-is-slow>#</a></h3>
<p>There are some unofficial sources which have published benchmarks for Apple MacBook Pro SSDs, but I wanna check by myself.</p>
<p>To do so, I&rsquo;ll use <a href=https://formulae.brew.sh/formula/fio target=_blank><code>fio</code></a>
(the Flexible IO CLI, but nobody I know calls it that), a disk benchmark tool. It has a lot of knobs (it&rsquo;s flexible!), and I encourage you to run <code>man fio</code> to check them out. However, we&rsquo;re only interested in knowing the write rate (mebibytes per second), so this is how we&rsquo;ll run it:</p>
<p><strong>NOTE</strong>: The following command will create a 100GiB file in the directory where its run. Think before you run it!</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>fio --name<span style=color:#f92672>=</span>write        <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --ioengine<span style=color:#f92672>=</span>posixaio <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --rw<span style=color:#f92672>=</span>write          <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --bs<span style=color:#f92672>=</span>1m             <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --numjobs<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>         <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --size<span style=color:#f92672>=</span>100g         <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --iodepth<span style=color:#f92672>=</span><span style=color:#ae81ff>8</span>         <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --end_fsync<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>       <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --direct<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>
</code></pre></div><p><strong>Flags explanation</strong></p>
<ul>
<li><code>--name=write</code>: Just a name for the fio &ldquo;job&rdquo;. It will use it for the output and the file it creates.</li>
<li><code>--ioengine=posixaio</code>: The IO engine for MacOS, POSIX Asynchronous IO.</li>
<li><code>--rw=write</code>: We&rsquo;re only interested in measuring performance with sequential writes.</li>
<li><code>--bs=1m</code>: A block size of 1MiB. If it was smaller, <code>fio</code> would need to make lots of repeated <code>write</code> syscalls, adding a lot of noise to the test (since they&rsquo;re expensive - more on this later).</li>
<li><code>--numjobs=1</code>: The number of parallel jobs performing IO (writing, in this case). Since we&rsquo;re doing sequential IO, adding more jobs won&rsquo;t do any good - they&rsquo;ll contend for file access.</li>
<li><code>--size=100g</code>: A big file!</li>
<li><code>--iodepth=16</code>: The queue of in-flight IO operations against the file. This is determined by a combination of the OS, the <code>fio</code> engine (<code>posixaio</code> in this case), and other factors. <code>fio</code>&rsquo;s output shows a distribution of the queue size, which helps determine the maximum value here. If a smaller-than-possible value is used, the benchmark might spend lots of time waiting for IO operations to be <em>acknowledged</em>. A value of 1 would make it behave synchronously.</li>
<li><code>--end_fsync=1</code>: Only consider the test done when the file is flushed to disk.</li>
<li><code>--direct=1</code>: Use direct IO (as opposed to buffered IO). In MacOS, this is controlled by <code>fcntl</code>&rsquo;s <code>F_NOCACHE</code> flag (see <code>man fcntl</code>). In Linux, this is equivalent to setting the <code>O_DIRECT</code> flag when opening a file.</li>
</ul>
<p>I will omit most of the output since right now we&rsquo;re only looking for the average write rate, expressed by the <code>bw</code> (bandwidth) output field, which in this case is ~5736MiB/s (I averaged it over multiple runs). If you&rsquo;re curious about what the rest of the output means, the <a href=https://fio.readthedocs.io/en/latest/fio_doc.html#interpreting-the-output target=_blank>official docs</a>
have a great explanation.</p>
<p>So now that we know the practical upper limit that we can hit with the generator, we can move on to it.</p>
<h3 id=considerations>Considerations<a hidden class=anchor aria-hidden=true href=#considerations>#</a></h3>
<h4 id=file-size>File size<a hidden class=anchor aria-hidden=true href=#file-size>#</a></h4>
<p>Simple one. We&rsquo;ll allow the file size to be configurable. However, since we&rsquo;re treating a 4KiB block as our unit, the file size will be 4KiB-aligned (that is, we must check that its size is a multiple of 4KiB).</p>
<h4 id=memory-limit>Memory limit<a hidden class=anchor aria-hidden=true href=#memory-limit>#</a></h4>
<p>The reason for using an external sorting algorithm is not having enough memory to hold the data being sorted. Therefore, we need to take care not to go over the available memory. We&rsquo;ll allow it to be configurable via a flag.</p>
<h4 id=parallelism>Parallelism<a hidden class=anchor aria-hidden=true href=#parallelism>#</a></h4>
<p>Generating random ASCII strings will be slow, so we&rsquo;ll benefit from using multiple threads. We&rsquo;ll use <a href=https://tokio.rs/ target=_blank>Tokio</a>
for that.</p>
<h4 id=saturation>Saturation<a hidden class=anchor aria-hidden=true href=#saturation>#</a></h4>
<p>The SSD must be saturated at all times, so that we don&rsquo;t add artificial bottlenecks.</p>
<h3 id=the-code>The code<a hidden class=anchor aria-hidden=true href=#the-code>#</a></h3>
<p>The strategy I followed is as follows:</p>
<ul>
<li>Create the file. In MacOS, the file is opened with Direct IO by default. In Linux, you&rsquo;ll need to be careful to open it with the <code>O_DIRECT</code> flag set.</li>
<li>Spawn a &ldquo;writer&rdquo; thread. It will hold a handle to the open file and receive strings over a channel, which it will write to the file. Since the strings are random, it won&rsquo;t do any ordering, writing them in a FIFO fashion.</li>
<li>Start threads to generate the random strings, sending them over the channel. This is where memory is allocated, so we must have a way to enforce the configured limit.</li>
</ul>
<h4 id=sidequest-limiting-memory>Sidequest: limiting memory<a hidden class=anchor aria-hidden=true href=#sidequest-limiting-memory>#</a></h4>
<script type=application/javascript src="https://gist.github.com/0x5d/d10c742fca7b23fea5cea5a5e9885e67.js?file=bucket.rs"></script>
<p>To make it easier to enforce the memory limit, I wrote a simple rate-limiting <a href=https://en.wikipedia.org/wiki/Token_bucket target=_blank>token bucket</a>
.</p>
<p>It&rsquo;s initialized with a <code>capacity</code>, and threads can <code>take</code> and <code>put</code> tokens back. If a thread tries to take a token when the bucket doesn&rsquo;t have any, it will sleep until a token is put back by another thread.</p>
<p>The implementation isn&rsquo;t perfect (e.g. it doesn&rsquo;t prevent putting tokens over the initial capacity), but it&rsquo;s enough.</p>
<h4 id=back-to-the-main-thing>Back to the main thing<a hidden class=anchor aria-hidden=true href=#back-to-the-main-thing>#</a></h4>
<p>Ok, back to random string generation. Here&rsquo;s the code in full. I&rsquo;ll go over each part.</p>
<script type=application/javascript src="https://gist.github.com/0x5d/d10c742fca7b23fea5cea5a5e9885e67.js?file=generate.rs"></script>
<p>First, the signature:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=color:#66d9ef>pub</span> <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>generate_data</span>(filepath: <span style=color:#66d9ef>&amp;</span><span style=color:#66d9ef>str</span>, size_bytes: <span style=color:#66d9ef>usize</span>, max_mem: <span style=color:#66d9ef>usize</span>) -&gt; <span style=color:#a6e22e>io</span>::Result<span style=color:#f92672>&lt;</span>()<span style=color:#f92672>&gt;</span>
</code></pre></div><p><code>generate_data</code> is an async function. It takes a <code>filepath</code> where the file will be created, the file&rsquo;s size, <code>size_bytes</code>, and the program&rsquo;s memory limit: <code>max_mem</code>. It returns an <code>io::Result</code> to communicate that it can fail.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=color:#66d9ef>if</span> (max_mem <span style=color:#66d9ef>as</span> <span style=color:#66d9ef>usize</span>) <span style=color:#f92672>&lt;</span> <span style=color:#66d9ef>crate</span>::BLOCK_SIZE {
    <span style=color:#66d9ef>return</span> io::Result::Err(Error::new(
        io::ErrorKind::Other,
        format!(
            <span style=color:#e6db74>&#34;Max allowed memory must be larger than {}B&#34;</span>,
            <span style=color:#66d9ef>crate</span>::BLOCK_SIZE
        ),
    ));
}
</code></pre></div><p>The max memory must be at least 1 block (4096B) - otherwise we won&rsquo;t be able to do anything! Here&rsquo;s a good place to make it clear that <code>max_mem</code> doesn&rsquo;t account for the memory things on the stack - pointers, numbers, etc.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=color:#66d9ef>let</span> file <span style=color:#f92672>=</span> File::create(filepath)<span style=color:#f92672>?</span>;
<span style=color:#66d9ef>let</span> num_cores <span style=color:#f92672>=</span> std::thread::available_parallelism()<span style=color:#f92672>?</span>.get();
<span style=color:#66d9ef>let</span> mem_per_core <span style=color:#f92672>=</span> max_mem <span style=color:#f92672>/</span> num_cores;
<span style=color:#66d9ef>let</span> b <span style=color:#f92672>=</span> Arc::new(bucket::Bucket::new(num_cores <span style=color:#66d9ef>as</span> <span style=color:#66d9ef>i32</span>));
<span style=color:#66d9ef>let</span> <span style=color:#66d9ef>mut</span> set <span style=color:#f92672>=</span> JoinSet::new();
<span style=color:#66d9ef>let</span> (tx, rx) <span style=color:#f92672>=</span> mpsc::channel();
</code></pre></div><p>Next up, the values used throughout the function at are initialized:</p>
<ul>
<li><code>file</code>: The file into which we&rsquo;ll write the random strings.</li>
<li><code>num_cores</code>: The number of cores available in the CPU.</li>
<li><code>mem_per_core</code>: The maximum amount of memory (in bytes) that each thread will be able to use.</li>
<li><code>b</code>: The <code>Bucket</code> that will serve as the memory-limiting mechanism. It&rsquo;s wrapped in an <code>Arc</code> so that it can be &ldquo;shared&rdquo; across threads.</li>
<li><code>set</code>: A Tokio <code>JoinSet</code>, which we&rsquo;ll use to keep track of the threads, and to join them when work is finished.</li>
<li><code>tx, rx</code>: The send and receive ends of a channel, which we&rsquo;ll use to transmit strings from the &ldquo;generator&rdquo; threads to the &ldquo;writer&rdquo; thread.</li>
</ul>
<p>About that&mldr;</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=color:#66d9ef>let</span> writer_handle <span style=color:#f92672>=</span> tokio::spawn(writer(file, b.clone(), rx, num_cores));
<span style=color:#75715e>// ...
</span><span style=color:#75715e></span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>writer</span>(
    <span style=color:#66d9ef>mut</span> file: <span style=color:#a6e22e>File</span>,
    b: <span style=color:#a6e22e>Arc</span><span style=color:#f92672>&lt;</span>Bucket<span style=color:#f92672>&gt;</span>,
    rx: <span style=color:#a6e22e>Receiver</span><span style=color:#f92672>&lt;</span>String<span style=color:#f92672>&gt;</span>,
) -&gt; <span style=color:#a6e22e>io</span>::Result<span style=color:#f92672>&lt;</span>()<span style=color:#f92672>&gt;</span> {
    <span style=color:#66d9ef>loop</span> {
        <span style=color:#66d9ef>let</span> s <span style=color:#f92672>=</span> rx.recv().map_err(<span style=color:#f92672>|</span>e<span style=color:#f92672>|</span> {
            Error::new(
                ErrorKind::Other,
                format!(<span style=color:#e6db74>&#34;Could not receive from channel: {e}&#34;</span>),
            )
        })<span style=color:#f92672>?</span>;
        <span style=color:#66d9ef>if</span> s <span style=color:#f92672>==</span> POISON_PILL {
            <span style=color:#66d9ef>return</span> Ok(());
        }
        b.put();
        file.write_all(s.as_bytes())<span style=color:#f92672>?</span>;
    }
}
</code></pre></div><p>The <code>writer</code> thread writes the strings it receives over <code>rx</code>, and <code>put</code>s back a token into the bucket, so any waiting generator threads are unblocked. When generation is finished, a <a href="https://aws.amazon.com/message-queue/features/#:~:text=Poison%20pills%20are%20special%20messages,in%20a%20client%2Fserver%20model." target=_blank><code>POISON_PILL</code></a>
value is sent, signaling it to stop.</p>
<p>Now, onto the main loop in <code>generate_data</code>:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=color:#66d9ef>let</span> <span style=color:#66d9ef>mut</span> remaining <span style=color:#f92672>=</span> size_bytes;
<span style=color:#66d9ef>while</span> remaining <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0</span> {
    <span style=color:#66d9ef>let</span> len <span style=color:#f92672>=</span> min(remaining, mem_per_core);
    remaining <span style=color:#f92672>-=</span> len;
    <span style=color:#66d9ef>let</span> tx <span style=color:#f92672>=</span> tx.clone();
    b.take();
    set.spawn_blocking(<span style=color:#66d9ef>move</span> <span style=color:#f92672>||</span> generate(tx, len));
}
</code></pre></div><p>Here, a new generator task is spawned for every <em>chunk</em> of string that must be generated, until there are no more <code>remaining</code> bytes. The string will be at most <code>mem_per_core</code> long. A token is taken from the bucket <code>b</code>, to prevent the program from going over the <code>max_mem</code>. <code>generate</code> is called, which generates a random string and sends it over <code>tx</code> so that the writer thread writes it to the file.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=color:#66d9ef>while</span> <span style=color:#66d9ef>let</span> Some(res) <span style=color:#f92672>=</span> set.join_next().<span style=color:#66d9ef>await</span> {
    <span style=color:#66d9ef>let</span> _ <span style=color:#f92672>=</span> res<span style=color:#f92672>??</span>;
}
tx.send(String::from(POISON_PILL))
    .map_err(<span style=color:#f92672>|</span>e<span style=color:#f92672>|</span> io::Error::new(ErrorKind::Other, e))<span style=color:#f92672>?</span>;

writer_handle.<span style=color:#66d9ef>await</span><span style=color:#f92672>?</span>
</code></pre></div><p>Finally, we join all the generator tasks, send the <code>POISON_PILL</code> message to the writer, and join it.</p>
<h3 id=the-moment-of-truth>The moment of truth<a hidden class=anchor aria-hidden=true href=#the-moment-of-truth>#</a></h3>
<p>According to the write rate output by <code>fio</code> (5736MiB/s), <em>just</em> writing 100GiB file should take around ~17.9 seconds. We should expect some overhead from the random string generation, though.</p>
<p>I created a <a href=https://github.com/0x5d/ext-sort/blob/main/src/main.rs#L33-L35 target=_blank>small CLI with the <code>clap</code> crate</a>
to make it easier to generate the file. Wrapping the call with <code>time</code> gives us:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>time ./target/release/ext-sort gen --file data.txt --size <span style=color:#ae81ff>107374182400</span>
./target/release/ext-sort gen --file data.txt --size <span style=color:#ae81ff>107374182400</span>  176.07s user 21.10s system 924% cpu 21.323 total
</code></pre></div><p>That&rsquo;s just over 3 seconds more than fio, which is a little bit of overhead. If you see any chances for reducing it, please let me know over at <a href=https://x.com/_0x5d target=_blank>Twitter</a>
or <a href=https://bsky.app/profile/0x5d.bsky.social target=_blank>Bluesky</a>
!</p>
<h2 id=the-real-friends-were-the-walls-we-crashed-into-along-the-way>The real friends were the walls we crashed into along the way<a hidden class=anchor aria-hidden=true href=#the-real-friends-were-the-walls-we-crashed-into-along-the-way>#</a></h2>
<blockquote>
<p>Soundtrack: <a href="https://youtu.be/ccLAgkz2eGI?si=iGSnoGf1BH429mi8" target=_blank>Turnstile - Endless</a>
</p>
<p><em>When I hit a wall I gotta BREAK. IN.</em></p>
</blockquote>
<p>Here are some things I ran into.</p>
<h3 id=always-use---profile-release>Always use <code>--profile release</code><a hidden class=anchor aria-hidden=true href=#always-use---profile-release>#</a></h3>
<p>&mldr; before you test performance. <code>cargo build</code> on its own doesn&rsquo;t apply all possible optimizations, to make compilation faster. The result is abysmal:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>cargo build
time ./target/debug/ext-sort gen --file data.txt --size <span style=color:#ae81ff>107374182400</span>
./target/debug/ext-sort gen --file data.txt --size <span style=color:#ae81ff>107374182400</span>  1825.21s user 28.37s system 963% cpu 3:12.48 total
</code></pre></div><p>3:12.48! That&rsquo;s over 9x more than with the release build.</p>
<h3 id=joinsetspawn_blocking-vs-joinsetspawn>JoinSet::spawn_blocking vs JoinSet::spawn<a hidden class=anchor aria-hidden=true href=#joinsetspawn_blocking-vs-joinsetspawn>#</a></h3>
<p>Using <code>spawn_blocking</code> yields slightly faster (~600ms for 100GiB files) run times than <code>spawn</code> in this case. This caught me off-guard at first, but upon inspection, this probably happens because in <code>generate</code>, <code>SmallRng::from_entropy()</code> issues a system call to <code>getentropy</code> (<code>getrandom</code> in Linux).</p>
<h3 id=filewrite-vs-filewrite_all>File::write vs File::write_all<a hidden class=anchor aria-hidden=true href=#filewrite-vs-filewrite_all>#</a></h3>
<p>The <code>write</code> docstring says it clearly:</p>
<blockquote>
<p>This function will attempt to write the entire contents of <code>buf</code>, but the entire write might not succeed [&mldr;]</p>
</blockquote>
<p>So if you wanna make sure the whole buffer is written to the file, call <code>write_all</code> (or do what <code>write_all</code> does, which is to call <code>write</code> as many times as needed).</p>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=http://0x5d.github.io/tags/rust/>rust</a></li>
<li><a href=http://0x5d.github.io/tags/algorithms/>algorithms</a></li>
</ul>
</footer>
</article>
</main>
<footer class=footer>
<span>&copy; 2024 <a href=http://0x5d.github.io/>nerv</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
</body>
</html>