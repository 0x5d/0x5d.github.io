[{"content":"I\u0026rsquo;ve been learning Rust in my free time for the last 6 months. I read The Book and I\u0026rsquo;m in the middle of reading Rust for Rustaceans (my notes so far), but after doing a couple of very small exercises and projects I wanted to do something more rusty.\nSo on Sundays, in between espressos and with very good company, I started writing an external sort.\nThis is the 1st post in a series, where I cover the code that generates the data to be sorted. Stay tuned for the next one!\n All the code \u0026amp; commands I\u0026rsquo;ll post here are running on my Macbook Pro M1 (32GiB, 1TB SSD). This is just for fun. The code is hosted in GitHub.\n The problem External sorting algorithms are used when the data that must be sorted can\u0026rsquo;t fit in memory. For example, my Mac has 32GiB of RAM. How can I sort a larger file?\nSo the basic idea is:\n you get a big file (bigger than memory), you split it into smaller chunks that fit in memory, you sort those chunks and write them to disk, you merge the sorted chunks and write the output, sorted.  I will go deeper into details as we go into my implementation.\nThe Solution Goals\n Make this thing fast af. Drink good espresso. Go into rabbit holes, learn about hardware, the OS, and performance.  Non-goals\n To write a production-ready Rust crate. This is just a fun exercise.  Sorting lots of random data Hold on, to sort lots of random data we need to start by -\nGenerating lots of random data  Soundtrack: Turnstile - Generator\n Ok, so the first thing we need is a way to generate random data. For this project, we\u0026rsquo;ll consider a 4KiB (AKA a \u0026ldquo;page\u0026rdquo;) ASCII string a unit or block of data. This will be the resolution we\u0026rsquo;ll be working at. The source file will be composed of many 4KiB strings with no gaps or delimiters.\nWriting* lots of random data fast* One of the Goals is to make this thing fast. So let\u0026rsquo;s think about that for a second - what does fast mean in this context? What determines the higher bound for time in this algorithm? It requires 3 things:\n Memory CPU IO (SSD)  If the input grows, we could add more CPU and memory, but IO speeds would remain constant - NVMe SSDs have a physical write speed limit, so we\u0026rsquo;ll probably be limited by it. Let\u0026rsquo;s see what that looks like.\nHow \u0026ldquo;fast\u0026rdquo; is \u0026ldquo;slow\u0026rdquo;? There are some unofficial sources which have published benchmarks for Apple MacBook Pro SSDs, but I wanna check by myself.\nTo do so, I\u0026rsquo;ll use fio (the Flexible IO CLI, but nobody I know calls it that), a disk benchmark tool. It has a lot of knobs (it\u0026rsquo;s flexible!), and I encourage you to run man fio to check them out. However, we\u0026rsquo;re only interested in knowing the write rate (mebibytes per second), so this is how we\u0026rsquo;ll run it:\nNOTE: The following command will create a 100GiB file in the directory where its run. Think before you run it!\nfio --name=write \\  --ioengine=posixaio \\  --rw=write \\  --bs=1m \\  --numjobs=1 \\  --size=100g \\  --iodepth=8 \\  --end_fsync=1 \\  --direct=1 Flags explanation\n --name=write: Just a name for the fio \u0026ldquo;job\u0026rdquo;. It will use it for the output and the file it creates. --ioengine=posixaio: The IO engine for MacOS, POSIX Asynchronous IO. --rw=write: We\u0026rsquo;re only interested in measuring performance with sequential writes. --bs=1m: A block size of 1MiB. If it was smaller, fio would need to make lots of repeated write syscalls, adding a lot of noise to the test (since they\u0026rsquo;re expensive - more on this later). --numjobs=1: The number of parallel jobs performing IO (writing, in this case). Since we\u0026rsquo;re doing sequential IO, adding more jobs won\u0026rsquo;t do any good - they\u0026rsquo;ll contend for file access. --size=100g: A big file! --iodepth=16: The queue of in-flight IO operations against the file. This is determined by a combination of the OS, the fio engine (posixaio in this case), and other factors. fio\u0026rsquo;s output shows a distribution of the queue size, which helps determine the maximum value here. If a smaller-than-possible value is used, the benchmark might spend lots of time waiting for IO operations to be acknowledged. A value of 1 would make it behave synchronously. --end_fsync=1: Only consider the test done when the file is flushed to disk. --direct=1: Use direct IO (as opposed to buffered IO). In MacOS, this is controlled by fcntl\u0026rsquo;s F_NOCACHE flag (see man fcntl). In Linux, this is equivalent to setting the O_DIRECT flag when opening a file.  I will omit most of the output since right now we\u0026rsquo;re only looking for the average write rate, expressed by the bw (bandwidth) output field, which in this case is ~5736MiB/s (I averaged it over multiple runs). If you\u0026rsquo;re curious about what the rest of the output means, the official docs have a great explanation.\nSo now that we know the practical upper limit that we can hit with the generator, we can move on to it.\nConsiderations File size Simple one. We\u0026rsquo;ll allow the file size to be configurable. However, since we\u0026rsquo;re treating a 4KiB block as our unit, the file size will be 4KiB-aligned (that is, we must check that its size is a multiple of 4KiB).\nMemory limit The reason for using an external sorting algorithm is not having enough memory to hold the data being sorted. Therefore, we need to take care not to go over the available memory. We\u0026rsquo;ll allow it to be configurable via a flag.\nParallelism Generating random ASCII strings will be slow, so we\u0026rsquo;ll benefit from using multiple threads. We\u0026rsquo;ll use Tokio for that.\nSaturation The SSD must be saturated at all times, so that we don\u0026rsquo;t add artificial bottlenecks.\nThe code The strategy I followed is as follows:\n Create the file. In MacOS, the file is opened with Direct IO by default. In Linux, you\u0026rsquo;ll need to be careful to open it with the O_DIRECT flag set. Spawn a \u0026ldquo;writer\u0026rdquo; thread. It will hold a handle to the open file and receive strings over a channel, which it will write to the file. Since the strings are random, it won\u0026rsquo;t do any ordering, writing them in a FIFO fashion. Start threads to generate the random strings, sending them over the channel. This is where memory is allocated, so we must have a way to enforce the configured limit.  Sidequest: limiting memory  To make it easier to enforce the memory limit, I wrote a simple rate-limiting token bucket.\nIt\u0026rsquo;s initialized with a capacity, and threads can take and put tokens back. If a thread tries to take a token when the bucket doesn\u0026rsquo;t have any, it will sleep until a token is put back by another thread.\nThe implementation isn\u0026rsquo;t perfect (e.g. it doesn\u0026rsquo;t prevent putting tokens over the initial capacity), but it\u0026rsquo;s enough.\nBack to the main thing Ok, back to random string generation. Here\u0026rsquo;s the code in full. I\u0026rsquo;ll go over each part.\n First, the signature:\npub async fn generate_data(filepath: \u0026amp;str, size_bytes: usize, max_mem: usize) -\u0026gt; io::Result\u0026lt;()\u0026gt; generate_data is an async function. It takes a filepath where the file will be created, the file\u0026rsquo;s size, size_bytes, and the program\u0026rsquo;s memory limit: max_mem. It returns an io::Result to communicate that it can fail.\nif (max_mem as usize) \u0026lt; crate::BLOCK_SIZE { return io::Result::Err(Error::new( io::ErrorKind::Other, format!( \u0026#34;Max allowed memory must be larger than {}B\u0026#34;, crate::BLOCK_SIZE ), )); } The max memory must be at least 1 block (4096B) - otherwise we won\u0026rsquo;t be able to do anything! Here\u0026rsquo;s a good place to make it clear that max_mem doesn\u0026rsquo;t account for the memory things on the stack - pointers, numbers, etc.\nlet file = File::create(filepath)?; let num_cores = std::thread::available_parallelism()?.get(); let mem_per_core = max_mem / num_cores; let b = Arc::new(bucket::Bucket::new(num_cores as i32)); let mut set = JoinSet::new(); let (tx, rx) = mpsc::channel(); Next up, the values used throughout the function at are initialized:\n file: The file into which we\u0026rsquo;ll write the random strings. num_cores: The number of cores available in the CPU. mem_per_core: The maximum amount of memory (in bytes) that each thread will be able to use. b: The Bucket that will serve as the memory-limiting mechanism. It\u0026rsquo;s wrapped in an Arc so that it can be \u0026ldquo;shared\u0026rdquo; across threads. set: A Tokio JoinSet, which we\u0026rsquo;ll use to keep track of the threads, and to join them when work is finished. tx, rx: The send and receive ends of a channel, which we\u0026rsquo;ll use to transmit strings from the \u0026ldquo;generator\u0026rdquo; threads to the \u0026ldquo;writer\u0026rdquo; thread.  About that\u0026hellip;\nlet writer_handle = tokio::spawn(writer(file, b.clone(), rx, num_cores)); // ... async fn writer( mut file: File, b: Arc\u0026lt;Bucket\u0026gt;, rx: Receiver\u0026lt;String\u0026gt;, ) -\u0026gt; io::Result\u0026lt;()\u0026gt; { loop { let s = rx.recv().map_err(|e| { Error::new( ErrorKind::Other, format!(\u0026#34;Could not receive from channel: {e}\u0026#34;), ) })?; if s == POISON_PILL { return Ok(()); } b.put(); file.write_all(s.as_bytes())?; } } The writer thread writes the strings it receives over rx, and puts back a token into the bucket, so any waiting generator threads are unblocked. When generation is finished, a POISON_PILL value is sent, signaling it to stop.\nNow, onto the main loop in generate_data:\nlet mut remaining = size_bytes; while remaining \u0026gt; 0 { let len = min(remaining, mem_per_core); remaining -= len; let tx = tx.clone(); b.take(); set.spawn_blocking(move || generate(tx, len)); } Here, a new generator task is spawned for every chunk of string that must be generated, until there are no more remaining bytes. The string will be at most mem_per_core long. A token is taken from the bucket b, to prevent the program from going over the max_mem. generate is called, which generates a random string and sends it over tx so that the writer thread writes it to the file.\nwhile let Some(res) = set.join_next().await { let _ = res??; } tx.send(String::from(POISON_PILL)) .map_err(|e| io::Error::new(ErrorKind::Other, e))?; writer_handle.await? Finally, we join all the generator tasks, send the POISON_PILL message to the writer, and join it.\nThe moment of truth According to the write rate output by fio (5736MiB/s), just writing 100GiB file should take around ~17.9 seconds. We should expect some overhead from the random string generation, though.\nI created a small CLI with the clap crate to make it easier to generate the file. Wrapping the call with time gives us:\ntime ./target/release/ext-sort gen --file data.txt --size 107374182400 ./target/release/ext-sort gen --file data.txt --size 107374182400 176.07s user 21.10s system 924% cpu 21.323 total That\u0026rsquo;s just over 3 seconds more than fio, which is a little bit of overhead. If you see any chances for reducing it, please let me know over at Twitter or Bluesky!\nThe real friends were the walls we crashed into along the way  Soundtrack: Turnstile - Endless\nWhen I hit a wall I gotta BREAK. IN.\n Here are some things I ran into.\nAlways use --profile release \u0026hellip; before you test performance. cargo build on its own doesn\u0026rsquo;t apply all possible optimizations, to make compilation faster. The result is abysmal:\ncargo build time ./target/debug/ext-sort gen --file data.txt --size 107374182400 ./target/debug/ext-sort gen --file data.txt --size 107374182400 1825.21s user 28.37s system 963% cpu 3:12.48 total 3:12.48! That\u0026rsquo;s over 9x more than with the release build.\nJoinSet::spawn_blocking vs JoinSet::spawn Using spawn_blocking yields slightly faster (~600ms for 100GiB files) run times than spawn in this case. This caught me off-guard at first, but upon inspection, this probably happens because in generate, SmallRng::from_entropy() issues a system call to getentropy (getrandom in Linux).\nFile::write vs File::write_all The write docstring says it clearly:\n This function will attempt to write the entire contents of buf, but the entire write might not succeed [\u0026hellip;]\n So if you wanna make sure the whole buffer is written to the file, call write_all (or do what write_all does, which is to call write as many times as needed).\n","permalink":"http://0x5d.github.io/posts/ext-sort/","summary":"I\u0026rsquo;ve been learning Rust in my free time for the last 6 months. I read The Book and I\u0026rsquo;m in the middle of reading Rust for Rustaceans (my notes so far), but after doing a couple of very small exercises and projects I wanted to do something more rusty.\nSo on Sundays, in between espressos and with very good company, I started writing an external sort.\nThis is the 1st post in a series, where I cover the code that generates the data to be sorted.","title":"Rust Adventures: External Sort, Chapter 1"},{"content":"Intro I\u0026rsquo;m really enjoying reading Jon Gjenset\u0026rsquo;s Rust for Rustaceans. I appreciated the author\u0026rsquo;s decision to assume his target audience to be people who had just finished The Book, making it sort of an expansion or a Level II.\nHowever, I found it light on contrasting examples, as well as images. I\u0026rsquo;m more of a visual learner, so I find them very useful to understand what\u0026rsquo;s right (or wrong), or to help me create a mental model of a concept being described.\nTherefore, to help me really grasp the topics discussed in the book, I\u0026rsquo;m writing the following notes. I decided to share them here in case they\u0026rsquo;re useful to someone else.\n ℹ️ I have written some of these notes out of my own intuition. If you find an incorrect explanation, or consider my mental model for a concept to be wrong, please let me know!\n  ℹ️ This is a WIP. I\u0026rsquo;ll add more entries as I make progress through the book and write more examples \u0026amp; explanations.\n  ⚠️ All the base code snippets I\u0026rsquo;m quoting here are © 2022 John Gjengset. Please buy the book, it\u0026rsquo;s a must-read if you\u0026rsquo;re serious about learning Rust.\n I\u0026rsquo;m dividing the post by chapters \u0026amp; sections within them. There might be missing sections, which would mean I didn\u0026rsquo;t feel the need to supplement my reading with additional examples.\nAnyway, enough talking. Here it is.\nChapter 1: Foundations Section 1.3: Borrowing and Lifetimes Generic Lifetimes This subsection talks about how sometimes you need to specify different lifetimes for different fields in your types (making your type generic over multiple lifetimes). Here\u0026rsquo;s the example presented in the book (playground).\nstruct StrSplit\u0026lt;\u0026#39;s, \u0026#39;p\u0026gt; { document: \u0026amp;\u0026#39;s str, delimiter: \u0026amp;\u0026#39;p str, } impl\u0026lt;\u0026#39;s, \u0026#39;p\u0026gt; Iterator for StrSplit\u0026lt;\u0026#39;s, \u0026#39;p\u0026gt; { type Item = \u0026amp;\u0026#39;s str; fn next(\u0026amp;mut self) -\u0026gt; Option\u0026lt;Self::Item\u0026gt; { todo!() } } fn str_before(s: \u0026amp;str, c: char) -\u0026gt; Option\u0026lt;\u0026amp;str\u0026gt; { StrSplit {document: s, delimiter: \u0026amp;c.to_string()}.next() } The author then mentions that making StrSplit generic over a single lifetime would cause a compilation error. Indeed, if we make the change\u0026hellip; (playground)\nstruct StrSplit\u0026lt;\u0026#39;s\u0026gt; { delimiter: \u0026amp;\u0026#39;s str, document: \u0026amp;\u0026#39;s str, } impl\u0026lt;\u0026#39;s\u0026gt; Iterator for StrSplit\u0026lt;\u0026#39;s\u0026gt; { // ... contents remain the same } fn str_before(s: \u0026amp;str, c: char) -\u0026gt; Option\u0026lt;\u0026amp;str\u0026gt; { StrSplit {document: s, delimiter: \u0026amp;c.to_string()}.next() } and run cargo build, we get the following error:\nerror[E0515]: cannot return value referencing temporary value --\u0026gt; src/main_wrong.rs:14:5 | 14 | StrSplit {document: s, delimiter: \u0026amp;c.to_string()}.next() | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^-------------^^^^^^^^ | | | | | temporary value created here | returns a value referencing data owned by the current function It becomes more evident if we mark the lifetimes using the notation used in The Book:\n//---------------------------+- s \u0026amp; c are \u0026#39;a fn str_before(s: \u0026amp;str, c: char) -\u0026gt; Option\u0026lt;\u0026amp;str\u0026gt; {// |  let delim = \u0026amp;c.to_string(); //--+- delim must also be \u0026#39;a |  StrSplit { // | |  document: s, // | |  delimiter: delim, // | |  } // | |  .next() // | |  //--+ delim is dropped | } // |  //---------------------------+ s \u0026amp; c live on! delim\u0026rsquo;s timeline is shorter than s\u0026rsquo;s and c\u0026rsquo;s, causing a contradiction: 'a \u0026lt; 'a.\nChapter 2: Types Section 2.2: Layout The explanation here comparing the default Rust in-memory representation vs the C-compatible one (repr(C)) is quite clear, but I thought a visual comparison would be helpful.\nThis is the example type used in the book:\n#[repr(C)] struct Foo { tiny: bool, normal: u32, small: u8, long: u64, short: u16, } As explained in page 21,\n Complex types - types that contain other types - are typically assigned the largest alignment of any type they contain.\n Therefore, this is its C-compatible layout, as described in page 22 (each square is 1B):\nBy visualizing it as a grid, it becomes clearer that the padding is determined by the field with the type that takes up the most space, long.\nAnd this would be Rust\u0026rsquo;s default layout (i.e. specifying #[repr(Rust)], or no repr attribute at all), which is 8B-aligned like the C-compatible layout, but which requires no padding between fields, reducing the total size to 16B.\nBonus Track: Alignment Modifiers The book doesn\u0026rsquo;t mention the alignment modifiers align and packed, which are only available for the C and Rust (default) representations, and can be used to \u0026ldquo;respectively raise or lower the alignment of structs and unions\u0026rdquo;.\nWhile reading about them, I again felt that their effects would be easier to understand and explain with a visual model.\npacked\nIf we add #[repr(C, packed(2))] to the Foo struct, the struct will be 2B-aligned. This is what it would look like (the \u0026ldquo;grid\u0026rdquo; visual model becomes less useful here, since padding and field alignment isn\u0026rsquo;t determined by a field\u0026rsquo;s size):\nThis can be verified with the following code (playground):\nuse std::mem; #[repr(C, packed(2))] struct Foo { tiny: bool, normal: u32, small: u8, long: u64, short: u16, } fn main() { assert_eq!(mem::align_of::\u0026lt;Foo\u0026gt;(), 2); assert_eq!(mem::size_of::\u0026lt;Foo\u0026gt;(), 18); } The layout for repr(Rust, packed(2)) is still the same as the one before, since 16B is 2B-aligned there was no padding.\nalign\nAs mentioned above, align raises the alignment. If we add #[repr(align(32))] (default representation, 32B-aligned) to Foo, this is what we get:\nThis basically adds a 16B padding to the memory occupied by the type. Again, this can be checked with the following code (playground).\nuse std::mem; #[repr(align(32))] struct Foo { tiny: bool, normal: u32, small: u8, long: u64, short: u16, } fn main() { assert_eq!(mem::align_of::\u0026lt;Foo\u0026gt;(), 32); assert_eq!(mem::size_of::\u0026lt;Foo\u0026gt;(), 32); } Trying out different values for packed and align was pretty interesting. I encourage anyone learning about them to do the same. You can also check your assumptions by first creating a layout diagram like the ones above (Excel works well, no need for fancy design software), and then asserting your guesses with align_of and size_of.\n","permalink":"http://0x5d.github.io/posts/rust-for-rustaceans/","summary":"Intro I\u0026rsquo;m really enjoying reading Jon Gjenset\u0026rsquo;s Rust for Rustaceans. I appreciated the author\u0026rsquo;s decision to assume his target audience to be people who had just finished The Book, making it sort of an expansion or a Level II.\nHowever, I found it light on contrasting examples, as well as images. I\u0026rsquo;m more of a visual learner, so I find them very useful to understand what\u0026rsquo;s right (or wrong), or to help me create a mental model of a concept being described.","title":"Notes on Rust For Rustaceans, Pt. 1"},{"content":"I\u0026rsquo;ll write the post I wish I\u0026rsquo;d read before I started writing RFCs at work. I\u0026rsquo;ll start by providing some motivation for RFCs, then go over my current process for writing them and provide a template that you can use.\nThis post isn\u0026rsquo;t by any means a formal specification for writing RFCs. If anything, it\u0026rsquo;s a loose framework I\u0026rsquo;ve found helpful over the past couple of years. I\u0026rsquo;m also writing this as a reference for myself in the future, but I hope it\u0026rsquo;ll be valuable for you too. It took me a while to appreciate the value of RFCs, but now I consider them one of the helpful tools I use regularly. If you\u0026rsquo;re an RFCs veteran, maybe this will give you a different perspective on them, and if you have tips, please share them! If you\u0026rsquo;ve never written an RFC, I hope when you\u0026rsquo;re finished reading this post you\u0026rsquo;ll feel confident enough to invest the time in one next time you get the chance.\nHold on - what\u0026rsquo;s an RFC? RFC stands for \u0026ldquo;Request for Comments\u0026rdquo;. It\u0026rsquo;s a structured document written in natural language explaining a proposal. Most of the time, RFCs are written for technical proposals. Still, they could be used to propose a change in an organizational process.\nWhy? I\u0026rsquo;ve found 3 main benefits of writing RFCs. They are each related to each general stage of the decision-making process: before, during and after. In short, I like that they facilitate an upfront analysis of the change and its implications, encourage asynchronous collaboration and thoughtful discussion, and serve as a future reference to understand how and why the decision was made.\nIn a healthy organization, this should also mean you\u0026rsquo;ll spend less time overall than if you had just dove right into coding. It often seems counter-productive, but after investing time into writing a good RFC, the path forward should be clearer and smoother in many ways.\nBefore: Upfront analysis Writing an RFC requires thoroughly exploring the problem and solution spaces. The problem might be something you discovered (e.g., a frequently-run query\u0026rsquo;s performance has degraded) or something given to you (e.g., a use-case discovered by the Product or Design team that the product should support). Nevertheless, the problem itself and the requirements stemming from it should be thoughtfully broken down.\nThis problem description and list of functional and non-functional requirements will be helpful when pondering the different alternatives to solve the problem. They effectively restrict the solution space, guiding you to the optimal - which might not be the \u0026ldquo;ideal\u0026rdquo; - solution.\nAt this point, it\u0026rsquo;s essential to identify co-authors, collaborators, stakeholders, and your audience.\n Co-authors will actively work on writing the RFC with you, committing time to think about it or parts of it. Collaborators are people who can guide you or help you bounce ideas off. For example, a team member who owns a subsystem your code will need to interact with, or a product team member who can help you understand the underlying use cases better. Stakeholders are any folks impacted by the RFC\u0026rsquo;s implementation. It\u0026rsquo;s a naturally \u0026ldquo;open\u0026rdquo; group that might include contributors who must prioritize new work, their managers, customers waiting for a specific feature, etc. Your audience is whoever you intend to get feedback from. You must identify it early as it will determine the style of writing you should use and the type of additional material you should include (such as diagrams, code snippets, or wireframes). If you fail to establish your audience, receiving high-quality feedback on your RFC will become more challenging. A clear sign of this is that commenters will usually ask you to explain something better or add more context. In those cases, your reaction shouldn\u0026rsquo;t be to exclude them from the review process - instead, try to understand their background and adapt your RFC to make it more digestible.  I\u0026rsquo;ve found the things I described in this section to help reduce the risk (both in magnitude and type) associated with your proposal.\nThe first risk dimension is resource utilization. If your RFC is approved, you\u0026rsquo;ll better understand what needs to be done, who should do it, and how long it will take. On the other hand, if it\u0026rsquo;s rejected, you won\u0026rsquo;t have wasted your valuable time working on a potentially-complex project only to find out it wasn\u0026rsquo;t needed. Arguably, our work as programmers isn\u0026rsquo;t to write as much code as possible but to minimize the amount of code that needs to be written.\nThe second is change management. Your proposal will inevitably affect the system it modifies. Thinking about the problem and solution in such a profound way will help you see how implementing your RFC will impact other components and users, making coming up with a migration strategy an easier task.\nThe third is the impact on people. If you\u0026rsquo;re writing an RFC, chances are the problem you\u0026rsquo;re tackling isn\u0026rsquo;t trivial. As stated above, it will probably require immediate changes in other components or systems and a timeline for rolling them out (migration). This means you\u0026rsquo;ll need to get the people responsible for those components to approve it. An RFC provides a great space to collaborate with them until everyone is onboard. If they have doubts, you can add more context to clarify everything. Suppose they spot a flaw in your understanding of how other components work. In that case, you can reassess and develop a better alternative. When your RFC has been approved by all the relevant people, they\u0026rsquo;ll have a clear picture of their role (or their teams' role) and plan accordingly.\nDuring: (Asynchronous) collaboration Some RFCs are simple - everyone knows the problem, and the solution is small in scope with a clear execution plan. Some are complex and require several people to write and review. In those cases, getting everyone on a video call is a sub-optimal way to get everyone\u0026rsquo;s thoughts. The most efficient way to write and review RFCs is with tools that enable asynchronous communication.\nWhen you\u0026rsquo;re collaborating with someone on authoring the document, it allows each of you to write and contribute when you\u0026rsquo;re the most productive. Furthermore, writing RFCs usually requires stepping away, drawing diagrams, reading existing code, and sketching solutions.\nFor the reviewers, it gives them time to read the whole document, take notes and think of insightful suggestions or meaningful questions. This is way more effective than forcing someone to provide an opinion on the spot. As an author, it also helps to digest the comments on your RFC, to prevent misunderstandings or spam. If you or someone uses the comments section of a shared document as a rapid-fire chat, people will tune off and ignore the conversation altogether.\nAdditionally, RFCs decouple definition from execution. The authors don\u0026rsquo;t necessarily need to be the ones to implement the solution described in it, reducing the bus factor in the team. Consider the alternative, where no RFC was written, and the person in charge switches teams or leaves the company altogether. Reading (sometimes, \u0026ldquo;deciphering\u0026rdquo;) the code they left behind is usually more time-consuming.\nAfter: Future reference After the RFC has been implemented, it\u0026rsquo;s still an invaluable resource, as people can refer back to it if they have questions about why things were done the way they were done. Sometimes, even the fundamental question of why they were done, regardless of the specific approach taken, isn\u0026rsquo;t obvious at all.\nIn such a dynamic (to put it lightly) industry, people will switch teams, and they will leave companies. And so will you, probably! Coming into a new team and having a set of well-written RFCs for the most relevant parts is a godsend.\nAnother minor - but still significant - side-effect of this is making it easier for folks who joined the team recently to empathize with employees with a longer tenure. It can be easy to judge someone harshly when you see a part of the codebase they contributed that doesn\u0026rsquo;t make sense. \u0026ldquo;Bad\u0026rdquo; code often can\u0026rsquo;t be taken at face value, and RFCs help with that. If the requirements were documented, they could say a lot about the context in which it was written and the constraints that limited the implementation.\nWhen? In time, you\u0026rsquo;ll instinctively know when to invest time into writing RFCs. However, a good rule of thumb is to review each of the above reasons for writing one (upfront analysis, collaboration, future reference) and consider whether any will be valuable to you (or future you!). If at least one of them seems like a good thing to have, chances are it\u0026rsquo;ll be time well spent. It\u0026rsquo;s easy to dismiss writing RFCs if your team is small and everyone is on the same page about what needs to be done. However, you\u0026rsquo;ll be surprised at how often your assumptions about how something works - or how it can be changed - turn out to be wrong. When that happens, it\u0026rsquo;s usually way better if you\u0026rsquo;re just writing a document instead of at the last commit of a colossal pull request.\nSimilarly, teams grow and change, and we forget things. If your company is small now, it doesn\u0026rsquo;t mean it will remain so forever. If it starts growing, you might need to hire people at an increasing rate, and RFCs will help them hit the ground running when they join. Also, when someone new asks you, \u0026ldquo;what were you thinking when you added this feature?!\u0026rdquo;, you can point them to the RFC and not worry about having to keep every detail in your mind.\nSomething to remember, though, is that not every change needs an RFC. Some problems are small and self-contained, and their solution obvious or not controversial. In those cases, clear commit messages and a comprehensive cover letter for your pull request will go a long way in documenting the change. When someone wants to learn more about a particular file, they can use git blame and read them.\nThere are no mathematical, completely objective rules to know when or not to invest your time in an RFC. If in doubt, talk to your team and understand their expectations.\nHow? When it\u0026rsquo;s time to get to work, I\u0026rsquo;ve used a loose strategy based on the above.\n Assess the problem and solution spaces - is an RFC needed? Identify co-authors, collaborators, stakeholders, and audience. Start writing! Take a look at the template. Share it and get feedback. When all feedback has been addressed, ensure your proposal is generally approved. Implement.  Let me expand on 4. \u0026amp; 5. When sharing an early draft, you\u0026rsquo;ll get a lot of feedback on the form, like a note you forgot to remove or requests to add visual material, expand on an idea, etc. If many people review it simultaneously at that stage, you\u0026rsquo;ll get a lot of similar comments. If readers perceive your RFC as a very \u0026ldquo;dirty\u0026rdquo; draft, they might not read it all (or at all). The idea is to refine these early on with a group of people that care a lot about the RFC, like your team or your manager. With those comments out of the way, you can expand the group of reviewers. The new round of comments should hopefully focus more on the content.\nWith regards to getting an RFC approved, it depends on the implicit or explicit agreements or policies within your organization. Some teams require sign-offs (e.g., reviewers mark the document as approved), while others may interpret the lack of outstanding feedback as approval. It\u0026rsquo;s all about communicating expectations effectively.\nClosing remarks Lastly, keeping an open mind is an essential part of the process. It\u0026rsquo;s a Request for Comments. You\u0026rsquo;re actively asking other people to review and critique your proposal. Some folks will like it a lot, while others might not. Even if the latter scenario doesn\u0026rsquo;t feel great, I\u0026rsquo;ve found that it\u0026rsquo;s usually the most helpful, assuming good faith and that no one\u0026rsquo;s gatekeeping anything (if you suspect that\u0026rsquo;s not the case, you might have a big culture problem on your hands!).\nIf someone isn\u0026rsquo;t convinced with your RFC, it could be that you haven\u0026rsquo;t considered all the alternatives. Sometimes, someone will reveal a major flaw in your RFC, causing its rejection. This might feel disheartening, but it\u0026rsquo;s actually a great outcome! That person saved you from wasting time pursuing an endeavor that wouldn\u0026rsquo;t have ended well. Go back to the drawing board, and try to get them involved so you can come up with an airtight solution.\n","permalink":"http://0x5d.github.io/posts/rfcs/","summary":"I\u0026rsquo;ll write the post I wish I\u0026rsquo;d read before I started writing RFCs at work. I\u0026rsquo;ll start by providing some motivation for RFCs, then go over my current process for writing them and provide a template that you can use.\nThis post isn\u0026rsquo;t by any means a formal specification for writing RFCs. If anything, it\u0026rsquo;s a loose framework I\u0026rsquo;ve found helpful over the past couple of years. I\u0026rsquo;m also writing this as a reference for myself in the future, but I hope it\u0026rsquo;ll be valuable for you too.","title":"On writing RFCs"}]